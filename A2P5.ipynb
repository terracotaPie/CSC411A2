{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7c2fc215-c9e1-4187-98e8-0a8fd9ac43e4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from numpy import random\n",
    "import scipy.stats\n",
    "\n",
    "import pickle as cPickle\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#Load the MNIST digit data\n",
    "M = loadmat(\"mnist_all.mat\")\n",
    "\n",
    "#Display the 150-th \"5\" digit from the training set\n",
    "#imshow(M[\"train5\"][150].reshape((28,28)), cmap=cm.gray)\n",
    "#show()\n",
    "\n",
    "\n",
    "def softmax(y):\n",
    "    '''Return the output of the softmax function for the matrix of output y. y\n",
    "    is an NxM matrix where N is the number of outputs for a single case, and M\n",
    "    is the number of cases'''\n",
    "    return exp(y) / tile(sum(exp(y), 0), (len(y), 1))\n",
    "\n",
    "\n",
    "def tanh_layer(y, W, b):\n",
    "    '''Return the output of a tanh layer for the input matrix y. y\n",
    "    is an NxM matrix where N is the number of inputs for a single case, and M\n",
    "    is the number of cases'''\n",
    "    return tanh(dot(W.T, y) + b)\n",
    "\n",
    "\n",
    "def forward(x, W0, b0, W1, b1):\n",
    "    L0 = tanh_layer(x, W0, b0)\n",
    "    L1 = dot(W1.T, L0) + b1\n",
    "    output = softmax(L1)\n",
    "    return L0, L1, output\n",
    "\n",
    "def deriv_multilayer(W0, b0, W1, b1, x, L0, L1, y, y_):\n",
    "    dCdL1 = y - y_\n",
    "    dCdW1 = dot(L0, dCdL1.T)\n",
    "    dCdobydodh = dot(W1, dCdL1)\n",
    "    one_minus_h_sq = 1 - L0**2\n",
    "\n",
    "    dCdW0 = tile(dCdobydodh, 28 * 28).T * dot(x, (one_minus_h_sq.T))\n",
    "    dCdb1 = dCdL1\n",
    "    dCdb0 = dCdobydodh * one_minus_h_sq\n",
    "\n",
    "    return dCdW1, dCdb1, dCdW0, dCdb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_):\n",
    "    return -sum(y_ * log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7543acf1-8358-4933-b7d4-d008fdf99f06"
    }
   },
   "outputs": [],
   "source": [
    "#Load sample weights for the multilayer neural network\n",
    "def load_sample_weights():\n",
    "    f = open(\"snapshot50.pkl\", \"rb\")\n",
    "    snapshot = cPickle.load(open(\"snapshot50.pkl\", \"rb\"), encoding=\"latin1\")\n",
    "    W0 = snapshot[\"W0\"]\n",
    "    b0 = snapshot[\"b0\"].reshape((300, 1))\n",
    "    W1 = snapshot[\"W1\"]\n",
    "    b1 = snapshot[\"b1\"].reshape((10, 1))\n",
    "    return W0,b0,W1,b1\n",
    "\n",
    "# L0, L1, output = forward(x, W0, b0, W1, b1)\n",
    "# y = argmax(output)\n",
    "\n",
    "# y_true = array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]).T\n",
    "# print(deriv_multilayer(W0, b0, W1, b1,x, L0, L1, output, y_true))\n",
    "################################################################################\n",
    "# Code for displaying a feature from the weight matrix mW\n",
    "# fig = figure(1)\n",
    "# ax = fig.gca()\n",
    "# heatmap = ax.imshow(W0[:, 50].reshape((28, 28)), cmap=cm.coolwarm)\n",
    "# fig.colorbar(heatmap, shrink=0.5, aspect=5)\n",
    "# show()\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch(offset,example_per_class=5):\n",
    "    # 5 examples per class\n",
    "    classes_num = 10\n",
    "    x_batch = np.zeros((example_per_class * classes_num, 28 * 28))\n",
    "    y_batch = np.zeros((example_per_class * classes_num, classes_num))\n",
    "    for i in range(classes_num):\n",
    "        for j in range(example_per_class):\n",
    "            x_batch[i * example_per_class + j] = M['train' + str(i)][j +\n",
    "                                                                     offset]\n",
    "            y_batch[i * example_per_class + j][i] = 1\n",
    "    return x_batch, y_batch, example_per_class * classes_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load one example from the training set, and run it through the\n",
    "def test_image(x):\n",
    "    _,_, output = forward(x, W0, b0, W1, b1)\n",
    "    return argmax(output)\n",
    "\n",
    "def test_performance_mult():\n",
    "    hit = miss = 0\n",
    "    for i in range(10):\n",
    "        for image in M[\"test\" + str(i)]:\n",
    "            result = test_image(image.reshape(784,1))\n",
    "            if result == i:\n",
    "                hit+=1\n",
    "            else:\n",
    "                miss+=1\n",
    "    return (float(hit)/float(hit + miss) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.26632851   3.49769574   8.13988462 ...,   2.84039219   9.96390563\n",
      "    0.39279594]\n",
      " [ -6.89337682   2.19824206  -6.55675103 ...,   3.92334454   0.25187001\n",
      "   -4.05619435]\n",
      " [ -1.84851291  -8.06161146   2.20786506 ...,  -6.32298993   0.18807834\n",
      "   -0.75498748]\n",
      " ..., \n",
      " [ -1.06677905   4.8458131  -11.01874563 ...,  -4.81548693   4.43243074\n",
      "   -8.4372785 ]\n",
      " [ -3.68593627   4.14081154  -2.41968924 ...,   9.07896377  -1.62498993\n",
      "    4.28396038]\n",
      " [  7.00829736  -8.38547935  -0.86335239 ...,  -2.08215517  -1.48149275\n",
      "   -3.08939501]]\n"
     ]
    }
   ],
   "source": [
    "noise = scipy.stats.norm.rvs(scale=5,size=784*50*10)\n",
    "noise = noise.reshape(500,784)\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Iter 500\n",
      "Iter 1000\n",
      "Iter 1500\n",
      "Iter 2000\n",
      "Iter 2500\n",
      "Iter 3000\n",
      "Iter 3500\n",
      "Iter 4000\n",
      "Iter 4500\n",
      "Iter 5000\n",
      "Iter 5500\n",
      "Iter 6000\n",
      "Iter 6500\n",
      "Iter 7000\n",
      "Iter 7500\n",
      "Iter 8000\n",
      "Iter 8500\n",
      "Iter 9000\n",
      "Iter 9500\n",
      "Iter 10000\n",
      "Iter 10500\n",
      "Iter 11000\n",
      "Iter 11500\n",
      "Iter 12000\n",
      "Iter 12500\n",
      "Iter 13000\n",
      "Iter 13500\n",
      "Iter 14000\n",
      "Iter 14500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do gradient Descent\n",
    "def train(plot=False):\n",
    "    global W0, b0, W1, b1\n",
    "    plot_iters = []\n",
    "    plot_performance = []\n",
    "    alpha = 1e-3\n",
    "    X, Y, examples_n = get_batch(0,50)\n",
    "    X += noise\n",
    "    for i in range(30):\n",
    "#         X, Y, examples_n = get_batch(i * 5,20)\n",
    "\n",
    "        update = np.zeros(4)\n",
    "\n",
    "        for j in range(examples_n):\n",
    "            y = Y[j].reshape((10, 1))\n",
    "            x = X[j].reshape((28 * 28, 1)) / 255.\n",
    "            L0, L1, output = forward(x, W0, b0, W1, b1)\n",
    "            gradients = deriv_multilayer(W0, b0, W1, b1, x, L0, L1, output, y)\n",
    "            update = [update[k] + gradients[k] for k in range(len(gradients))]\n",
    "            if (i * examples_n + j) % 500 == 0: \n",
    "                print(\"Iter %d\" % (i * examples_n + j))\n",
    "            \n",
    "        # update the weights \n",
    "#         print(\"Updating over batch %s\" % update)\n",
    "        W1 -= alpha * update[0]\n",
    "        b1 -= alpha * update[1]\n",
    "        W0 -= alpha * update[2]\n",
    "        b0 -= alpha * update[3]\n",
    "        if plot:\n",
    "            plot_iters.append(i * examples_n)\n",
    "            plot_performance.append(test_perf())\n",
    "    return plot_iters,plot_performance\n",
    "W0,b0,W1,b1 = load_sample_weights()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_descent(f, df, x, y, init_t, alpha):\n",
    "    EPS = 1e-5\n",
    "    prev_t = init_t-10*EPS\n",
    "    t = init_t.copy()\n",
    "    max_iter = 10000\n",
    "    iter  = 0\n",
    "    while iter < max_iter:\n",
    "        prev_t = t.copy()\n",
    "        t -= alpha*df(x, y, t)\n",
    "        if iter % 500 == 0:\n",
    "            print(\"Iter %d\" % iter)\n",
    "        iter += 1\n",
    "    return t\n",
    "\n",
    "def test_performance_linear(theta):\n",
    "    hit = miss = 0\n",
    "    for i in range(10):\n",
    "        for image in M[\"test\" + str(i)]:\n",
    "            result = np.dot(np.append(ones(1),image/255.),theta.T)\n",
    "            if result.argmax() == i:\n",
    "                hit+=1\n",
    "            else:\n",
    "                miss+=1\n",
    "    return (float(hit)/float(hit + miss)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Iter 500\n",
      "Iter 1000\n",
      "Iter 1500\n",
      "Iter 2000\n",
      "Iter 2500\n",
      "Iter 3000\n",
      "Iter 3500\n",
      "Iter 4000\n",
      "Iter 4500\n",
      "Iter 5000\n",
      "Iter 5500\n",
      "Iter 6000\n",
      "Iter 6500\n",
      "Iter 7000\n",
      "Iter 7500\n",
      "Iter 8000\n",
      "Iter 8500\n",
      "Iter 9000\n",
      "Iter 9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x, y, theta):\n",
    "    x = hstack((ones((x.shape[0],1)), x))\n",
    "    return sum(sum((y - dot(x,theta.T)) *7* 2))\n",
    "\n",
    "\n",
    "def df(x, y, theta):\n",
    "    x = hstack( (ones((x.shape[0],1)), x))\n",
    "    return 2 * dot((dot(x,theta.T) - y).T,x)\n",
    "\n",
    "X,Y,n = get_batch(0,50)\n",
    "X = X/255. + noise \n",
    "theta0 = np.zeros(10 * 785)\n",
    "theta0 = theta0.reshape(10,785)\n",
    "theta = grad_descent(f, df, X, Y, theta0, 1e-7)\n",
    "test_performance_linear(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear performance      | 43.54\n",
      "Multinomial performance | 82.92\n"
     ]
    }
   ],
   "source": [
    "result_lin = test_performance_linear(theta)\n",
    "result_mult = test_performance_mult()\n",
    "print(\"Linear performance      | %.2f\" % result_lin)\n",
    "print(\"Multinomial performance | %.2f\" % result_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF41JREFUeJzt3XuM3NV1B/Dv+c3u+rFeP9bYjgNODMHmURpMu4I0gYY0\nL4KoDGqKQE3kKChGCpCgJlFSIjWgShVqQhIi2iROcDFVeKQlBFohKFiklKikLMExz/CKXez4hZ/r\ntb2v3+kfO1QL2fs9w87uzLj3+5Es787Z3/zu/mbOzu6ce881d4eI5Kdo9gBEpDmU/CKZUvKLZErJ\nL5IpJb9IppT8IplS8otkSskvkiklv0im2hp5so5ihs9om53+gmi2odnET16WPB6emx0bnLuecddy\nPAuPBN93cN8eXDerVPj9s+taBK890WNWBNeFHR+NOzp3JHrMhkfSsTY+NifHHvF+DPqRmp5wdSW/\nmZ0H4EYAFQA/dPfr2dfPaJuN9y66JBn34WF+vvb2dDBIXu/v5/EgSYw8mD5CHkgA1l7nz9hp0/j9\nkyQqD/TxY4Oxlf2HabyYO4fGQR5TmzmDHuqH+LltOr8u3n8ofew8Pm4/yJ8vEfpcBVDu25+MFfPm\n0mNHXtuTjD02dD8f2Njz1PyVb2JmFQB/D+BjAE4FcKmZnTrR+xORxqrnb/4zAbzk7q+4+yCAOwCs\nnJxhichUqyf5jwXw6pjPt1RvewMzW21mvWbWO1jyX+NEpHGm/N1+d1/j7j3u3tNR8L/xRKRx6kn+\nrQCWjPn8uOptInIUqCf5HwewzMyON7MOAJcAuHdyhiUiU23CNSh3HzazKwE8gNFS31p3f4YeVJa8\nfNPGh+OHybF11tLDslPfwXQsKvV1dPCTB8djYIDHp0+f+Lk7eEkqenUoDxyg8XAeAOO8/EqfDwCd\nB+BHgmtaJx8YpPHibQvTx+7n5dli9qxkzPbV/npeVwHa3e8DcF899yEizaHpvSKZUvKLZErJL5Ip\nJb9IppT8IplS8otkqqHr+QHnNe1ofTY7Nlj2Gq1rZ8tiAcBIXRZBTTdcqmy8Fh8tN2bxMliaGi7J\nDRRd6ZozAGBwKB0L5nWw5cAAwjkK7DGN6vw+WN9jGrE6ljrTeR9vYQMuvfKLZErJL5IpJb9IppT8\nIplS8otkSskvkqnGlvrMaHmGdTQFgKKrKx0MlsWWh9KdXAHAgtIO9u5LHzsjKM1ES1ODZa9RJ1i2\nfJQt/wQQltOMXXPUsDSWPN5RR+WovXYxl7SBBzD8m83JmLXz8mpl4TE0XlenaYBe97DjclDirJVe\n+UUypeQXyZSSXyRTSn6RTCn5RTKl5BfJlJJfJFMNXtJrtHZbzO+mR7N5AFGL6mLmTBqPlnDanHRN\nudyd3jUVAIp58/i5+4K6bnBdaC092Om2mM3r+JH+s46n8b7V6cfs389YS4899/HVNL7g+3x+xYx9\npK14hb/ulWReBwBYZyc/fn/Q0py0mg+X9NI7rv1L9covkiklv0imlPwimVLyi2RKyS+SKSW/SKaU\n/CKZqqvOb2abAPQBGAEw7O499AB33nY4aOVckPbcddVGgbhtOFl/TfsMAOF6/mjduh85wo8nvQzC\n1twlH9vAiaRlOYC//c73aHxJW7qPwpyCP2ZPnnUrjT+xgobxN+89PxmL1syXwfbfRdSDIWpLzp4T\nQat23rK89kL/ZEzy+YC7vzYJ9yMiDaRf+0UyVW/yO4CHzOwJM+NzMUWkpdT7a//Z7r7VzBYCeNDM\nnnf3R8Z+QfWHwmoAmF7w+dAi0jh1vfK7+9bq/zsB3A3gzHG+Zo2797h7T4fV+aaciEyaCSe/mXWa\nWdfrHwP4CICnJ2tgIjK16vm1fxGAu6tLE9sA3Obu90/KqERkyk04+d39FQCnv6WDDLSmbdE226QX\nergeP1rPH+wZQNfzB8dW5s3l5/ZgX+VgTwKU6eM92KK77wPLafzq62+n8dM7+HUfQfrxfnKQ17MP\nlfz5cGI7XzO/9/3pXgNzH3qBHlsJ1uuHhoLnI9nrwYeDx5s+H2rfo1ulPpFMKflFMqXkF8mUkl8k\nU0p+kUwp+UUy1fjW3QVfCklFJTEiaq8dlduMLekNyohlf7A9eFTiDNpMw9Lx/eeeQA+95Fo+NeMP\npv2WxncFVakuslT6zj1n0WMf/iGP33/NN2j83m/ckIydddcX6LHLvthL41E7dlZ+BeIlxfzk5PkQ\nnPcNdzPxEYjI0UzJL5IpJb9IppT8IplS8otkSskvkiklv0imGlzn96BlMS8a09oo2fIYAKxrFo8P\nDtG4H0m3HHcyBwCItw+PWpbTducA9tyRbq/9vVO+Q499exsf+7ygvfbekrcV30Me7k/P/zk99oHZ\n76Hxz25aSeP/8q6HkrGFJ+2ix1YWHEPjHszdwIzpNGzsuR607qZt6g/XPo9Gr/wimVLyi2RKyS+S\nKSW/SKaU/CKZUvKLZErJL5Kpxtb5HbSGWQ4E695Z7TSqlQfrnMPW39PJ9uDGa7pR+2y+5TJw6JyT\naPzbJ6e3yZ5T8PkL20f4dfvLVz9I4//9s1No/D8+8fVk7MURPodg8WN8m+xNry2j8W1f+2kyVrGJ\n94YA4v4PBWkzDwDO5pVE/RvUultE6qHkF8mUkl8kU0p+kUwp+UUypeQXyZSSXyRTYZ3fzNYCuADA\nTnc/rXpbN4A7ASwFsAnAxe6+t97BWFDvpvXNqM7P+ggAsPaJT3nwQ7webbP4ds9955xI41+/4R9o\n/MT29Jr6HSN8ffeXXv44jbd9mvdJmMOnAeCcO7+UjC2/he+l0L59M40vfJ4/ZjOvS3/vN53Etx7/\n3FlX0fis/3yJxsv9fPvwYnYXOZg/V2lfi6AXwBvGUMPX3ALgvDfd9hUA6919GYD11c9F5CgSJr+7\nPwLgzT+iVwJYV/14HYALJ3lcIjLFJvo3/yJ331b9eDuARZM0HhFpkLrf8PPRSc7JCcVmttrMes2s\nd9B5vzcRaZyJJv8OM1sMANX/d6a+0N3XuHuPu/d0BAtgRKRxJpr89wJYVf14FYB7Jmc4ItIoYfKb\n2e0A/gvASWa2xcwuA3A9gA+b2YsAPlT9XESOImFx290vTYSCCu84DHStsh/m7wnQ/vfRsZ0zabyM\navWd6XPTmi2Aw6cdR+MHP7Wfxv8w3UoAAPDIkdnJ2KMHeS+AHfe8g8bffuA5Gj/mtidpfOHi9HvB\n5Wu8zk/70wNAsF/Ca2ReyPJ2Pv+h/7J9ND7r0WCfiGAfCSd7MUR5wPaJiPoMjKUZfiKZUvKLZErJ\nL5IpJb9IppT8IplS8otkqrGtu81gpKWxTeM1LbaUMSqt4C2UQMY/ebps5AU/d/tf7aDxB5ffSeMb\nB/lS5y9fvzoZW/A4LyO+rY0vPS0P8XbqRbD1ebkt/b1HW5d7tCx27hwabycPy56St2o/ZX5y0ioA\nYPcA304+XJ5OWnezNvEAbxVvw7W/nuuVXyRTSn6RTCn5RTKl5BfJlJJfJFNKfpFMKflFMtXYOj9A\n6+1022KAtzQOasZlf7D9d1SXLdJLQA+cczw9dP3JN9F4X9Bt+cqvfo7GF/zr08mYBS3Nw3j3PBr3\n8LqSxyVol24Vvux2ZDfvFs9e2aYH80Lai6COP40/36Llxk6WG0fft00jz9VovssYeuUXyZSSXyRT\nSn6RTCn5RTKl5BfJlJJfJFNKfpFMNbjObwCrYQ7wNdZsHkDUPtsP8rqrzQrWpe9Nt3J+95d/RY99\nZYjPX7hu65/SePcjr9J4ye4/qvuybc8BoHMujw8H9XDSqn2EXFMgnoNQedtCGj+uLf2YHix5e+zu\n9n4a3zESpE47nwcQ1fIZZ4+3WneLSETJL5IpJb9IppT8IplS8otkSskvkiklv0imwjq/ma0FcAGA\nne5+WvW2awF8BsCu6pdd4+73RfflQ0MY/u22ZLwSrB2vLFqQvu/DfIvtYj6/73I779O+6xNnJGPf\nXHADPXZ+hdden/g530Z72dDLNM7613swdyJSBmvmI2zdejGTb5sebdHtwZ4Cvxk6mIzNLfjr3k+f\nPZ3Glw/8msaLYOzlvvTYwzkrwbyRWtXyyn8LgPPGuf1b7r6i+i9MfBFpLWHyu/sjAPY0YCwi0kD1\n/M1/lZltNLO1ZsZ/pxaRljPR5P8ugBMArACwDUDyj14zW21mvWbWO4SBCZ5ORCbbhJLf3Xe4+4i7\nlwB+AOBM8rVr3L3H3XvawTcgFJHGmVDym9niMZ9eBCDdPlZEWlItpb7bAZwL4Bgz2wLgawDONbMV\nABzAJgCXT+EYRWQKhMnv7peOc/PNEzmZFQWKGen6p01P7zsO8Fq+BTVj70vXfAHAgz7rg3PS6+JP\naOc9/x84xPeRf9eP+2jcgjX5rJZfHuTr0qM18eXOXTQerbmn/RuCvRJ8Lq93P3fFcTTeWaSv2+Wb\neQ+Fk/+aF7i8s5PGywP8MaVzM/r5Y4Zp7M9n9e0XkYCSXyRTSn6RTCn5RTKl5BfJlJJfJFONbd1d\nFLAu0iI7WGbJ2kyX+/bzU3fzFtRFULJyUkHZPMyXzXYYb29dvLyVxjGdz4xk20VXgq2kyz3BNtcz\nePnVuqKW6emylQUl0mev5CXSxy/4Fo3/W3966/RX1i2nxy7c/QyNI7ouUdl6gEx1D9p+gx2r1t0i\nElHyi2RKyS+SKSW/SKaU/CKZUvKLZErJL5KpBm/RDaBM1yG9jy+DZFitGwB8L58HYEFrb7ZScgFZ\nOgoA5/38L2j8lM4dNO79vEW1D6bnGVgHvy7FPD7/IWqJzs4NAIOnp2vtWz7LW1BveO+NNP7Rjato\nvHtV+jFfWPLW22Hb8CN8i++oVs+WYRedfHk6Oshy4oO1v57rlV8kU0p+kUwp+UUypeQXyZSSXyRT\nSn6RTCn5RTLV2Dp/WdL6aNSimq6hZmucUUPdNmjtXSFl3T1lSY/9wdnraPyGw++n8ajWHq2pp/cd\ntJi2YLvoF656B43/88XfTsa6Cl7n/+jGT9H43JX/Q+PoJG3iSetsAPCgP4QfCZ5vQZ2fzUuJ5hCM\nHEg/V32k9u279covkiklv0imlPwimVLyi2RKyS+SKSW/SKaU/CKZCuv8ZrYEwK0AFgFwAGvc/UYz\n6wZwJ4ClADYBuNjdeRP49jYUC+Ynw+X2nXwsh8kcgWANdLRVddQPwEg79GnB9ISlbbxm/MJ33knj\n7/hH/jN62vb097btA9302NkXbKPxzx+/nsYv6NxN4w8fnp2MfXLDn9FjZ9/G5xgUs4NttNnzJajT\nh9jW4wCswh8zH0hvCe8jfN5IhexBYXv5uMaq5ZV/GMAX3P1UAO8BcIWZnQrgKwDWu/syAOurn4vI\nUSJMfnff5u6/rH7cB+A5AMcCWAng9alr6wBcOFWDFJHJ95b+5jezpQDOAPALAIvc/fXfGbdj9M8C\nETlK1Jz8ZjYLwF0Arnb3A2Nj7u4YfT9gvONWm1mvmfUOjvBedCLSODUlv5m1YzTxf+TuP6nevMPM\nFlfjiwGM+26du69x9x537+moBI0JRaRhwuS30aV2NwN4zt2/OSZ0L4DX26euAnDP5A9PRKZKLUt6\n3wfgkwCeMrMN1duuAXA9gB+b2WUANgO4OLynoWGUO3al48GSXmfbD0fLXqPlwsHWxmyL7q6Cl1cq\nJd+i+5lz19D43T0LaXzXcLqcdlEX32p6yzBf6vzuDj7263b20Pjtj70nGTv1us30WICXEX0oXS4D\nACPbrkdbukelvPD5QlpzA0FpOdguHs5LgbUKk9/dH0W6a/0HJ2UUItJwmuEnkiklv0imlPwimVLy\ni2RKyS+SKSW/SKYa27q7UqAgraCjrajRToYb1Nqj2ihb/gkAC3vTy2a/uPVD9NibjvsZjW8Z5stL\n/2TmFhpnZhp/iF/ydhr/vQdX0/jJVz5P46d2kVp+Oz+37z9A4wi2Rmf18qJrFj20DFqaF7PINtmo\nYWvzoXSL7Whb9XIvGVuwHHgsvfKLZErJL5IpJb9IppT8IplS8otkSskvkiklv0imGlvnHx5BuXdf\nMmzTp9HDLagLM6xVMgAY2/4bQNsr6RbXm764nB57yp+fRuPrV95A45uGed13aVt67fjvP3gFPXb5\n9/mWzqc8+yKNl8P8utLtpkmtGwA8uG+2Xh8ArXlH22BbB3+uRa3go++NtZqP5rvYDNKDYbD213O9\n8otkSskvkiklv0imlPwimVLyi2RKyS+SKSW/SKaM9sKfZHPaF/ofdX88/QVBf/spVQbXYSQ9tnB7\n8GBdelivnsbnP3hfen13tDY8uu+I9wf17jJda7cuvgW3Hwr6O0TPXdJ7vwgeM7beHoiv68iu12i8\nmDnx3at8MD2v47Ej92F/uTtodFAdw4RHICJHNSW/SKaU/CKZUvKLZErJL5IpJb9IppT8IpkK1/Ob\n2RIAtwJYBMABrHH3G83sWgCfAbCr+qXXuPt9/M4Aa0vXXn0o6DnOepJHPdwtiFd4fGTv3vShQS+A\nYs5sGvcjvG9/9L0Z6SFvQX96PxjU0gPRuncfJPXyaL1+1N8hqLXT6xrMrfCgbz+G+NiLpUv48bvT\nfS3Cx5s934aC/SvGqKWZxzCAL7j7L82sC8ATZvZgNfYtd/9GzWcTkZYRJr+7bwOwrfpxn5k9B+DY\nqR6YiEytt/Q3v5ktBXAGgF9Ub7rKzDaa2Vozm5c4ZrWZ9ZpZ72DJtzASkcapOfnNbBaAuwBc7e4H\nAHwXwAkAVmD0N4NxG9G5+xp373H3no6C9B4TkYaqKfnNrB2jif8jd/8JALj7DncfcfcSwA8AnDl1\nwxSRyRYmv5kZgJsBPOfu3xxz++IxX3YRgKcnf3giMlVqebf/fQA+CeApM9tQve0aAJea2QqMlv82\nAbg8vCd3uhwxLHmRJZxRyQnGf87ZTP4nSWXeuG9pjGLlLAAejS3gh/h7JWzs5bYd9Nhi7hx+8mgb\n7QH+mBXz5qaPDZYD2yxeIh3ZvpPGK8fMJ8cG1yUoz0bLtIu9PLVYGZO1t4+ODZc5j1HLu/2PAhiv\n8Mhr+iLS0jTDTyRTSn6RTCn5RTKl5BfJlJJfJFNKfpFMNXaLbhhQpJcc1rVFd7Bk1w/zWnnYgpq0\ngY6Wd6IMar7BHAOLvrcBMnciqPuyYwEAUTxa0svmKATt0j2qpQfLlct9+9PHRsusg22yi/ndNB7O\n/RhOt4IvFi3gx7LtwWtq2l09T+1fKiL/nyj5RTKl5BfJlJJfJFNKfpFMKflFMqXkF8lUQ7foNrNd\nADaPuekYAHwv4+Zp1bG16rgAjW2iJnNs73R3PlGgqqHJ/zsnN+t1956mDYBo1bG16rgAjW2imjU2\n/dovkiklv0immp38a5p8fqZVx9aq4wI0tolqytia+je/iDRPs1/5RaRJmpL8Znaemf3azF4ys680\nYwwpZrbJzJ4ysw1m1tvksaw1s51m9vSY27rN7EEze7H6P+kp3vCxXWtmW6vXboOZnd+ksS0xs4fN\n7Fkze8bMPl+9vanXjoyrKdet4b/2m1kFwAsAPgxgC4DHAVzq7s82dCAJZrYJQI+7N70mbGZ/DOAg\ngFvd/bTqbX8HYI+7X1/9wTnP3b/cImO7FsDBZu/cXN1QZvHYnaUBXAjgU2jitSPjuhhNuG7NeOU/\nE8BL7v6Kuw8CuAPAyiaMo+W5+yMA9rzp5pUA1lU/XofRJ0/DJcbWEtx9m7v/svpxH4DXd5Zu6rUj\n42qKZiT/sQBeHfP5FrTWlt8O4CEze8LMVjd7MONYVN02HQC2A1jUzMGMI9y5uZHetLN0y1y7iex4\nPdn0ht/vOtvdVwD4GIArqr/etiQf/Zutlco1Ne3c3Cjj7Cz9f5p57Sa64/Vka0bybwWwZMznx1Vv\nawnuvrX6/04Ad6P1dh/e8fomqdX/+YZ1DdRKOzePt7M0WuDatdKO181I/scBLDOz482sA8AlAO5t\nwjh+h5l1Vt+IgZl1AvgIWm/34XsBrKp+vArAPU0cyxu0ys7NqZ2l0eRr13I7Xrt7w/8BOB+j7/i/\nDOCrzRhDYlwnAPhV9d8zzR4bgNsx+mvgEEbfG7kMwHwA6wG8COAhAN0tNLZ/AvAUgI0YTbTFTRrb\n2Rj9lX4jgA3Vf+c3+9qRcTXlummGn0im9IafSKaU/CKZUvKLZErJL5IpJb9IppT8IplS8otkSskv\nkqn/BQnIthXU5dyzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64226a0668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize noisy image\n",
    "X,Y,n = get_batch(0,50)\n",
    "X += noise\n",
    "noisy_image = X[0].reshape((28,28))\n",
    "output = plt.imshow(noisy_image)\n",
    "plt.savefig(\"images/noise_image.png\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "9f653140-596b-4ece-983f-6b6a0765482c",
    "theme": {
     "11bff249-c502-4f61-a38e-5981accf77e9": {
      "id": "11bff249-c502-4f61-a38e-5981accf77e9",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     },
     "789f2b12-a5e2-45e2-a9f3-007920927d25": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "789f2b12-a5e2-45e2-a9f3-007920927d25",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "9f653140-596b-4ece-983f-6b6a0765482c": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "9f653140-596b-4ece-983f-6b6a0765482c",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         0,
         43,
         54
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         232,
         213
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         38,
         139,
         210
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         147,
         161,
         161
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Lato",
       "font-size": 5
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
