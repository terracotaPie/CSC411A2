{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7c2fc215-c9e1-4187-98e8-0a8fd9ac43e4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from numpy import random\n",
    "\n",
    "import pickle as cPickle\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#Load the MNIST digit data\n",
    "M = loadmat(\"mnist_all.mat\")\n",
    "\n",
    "#Display the 150-th \"5\" digit from the training set\n",
    "#imshow(M[\"train5\"][150].reshape((28,28)), cmap=cm.gray)\n",
    "#show()\n",
    "\n",
    "\n",
    "def softmax(y):\n",
    "    '''Return the output of the softmax function for the matrix of output y. y\n",
    "    is an NxM matrix where N is the number of outputs for a single case, and M\n",
    "    is the number of cases'''\n",
    "    return exp(y) / tile(sum(exp(y), 0), (len(y), 1))\n",
    "\n",
    "\n",
    "def tanh_layer(y, W, b):\n",
    "    '''Return the output of a tanh layer for the input matrix y. y\n",
    "    is an NxM matrix where N is the number of inputs for a single case, and M\n",
    "    is the number of cases'''\n",
    "    return tanh(dot(W.T, y) + b)\n",
    "\n",
    "\n",
    "def forward(x, W0, b0, W1, b1):\n",
    "    L0 = tanh_layer(x, W0, b0)\n",
    "    L1 = dot(W1.T, L0) + b1\n",
    "    output = softmax(L1)\n",
    "    return L0, L1, output\n",
    "\n",
    "def deriv_multilayer(W0, b0, W1, b1, x, L0, L1, y, y_):\n",
    "    dCdL1 = y - y_\n",
    "    dCdW1 = dot(L0, dCdL1.T)\n",
    "    dCdobydodh = dot(W1, dCdL1)\n",
    "    one_minus_h_sq = 1 - L0**2\n",
    "\n",
    "    dCdW0 = tile(dCdobydodh, 28 * 28).T * dot(x, (one_minus_h_sq.T))\n",
    "    dCdb1 = dCdL1\n",
    "    dCdb0 = dCdobydodh * one_minus_h_sq\n",
    "\n",
    "    return dCdW1, dCdb1, dCdW0, dCdb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_):\n",
    "    return -sum(y_ * log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7543acf1-8358-4933-b7d4-d008fdf99f06"
    }
   },
   "outputs": [],
   "source": [
    "#Load sample weights for the multilayer neural network\n",
    "def load_sample_weights():\n",
    "    f = open(\"snapshot50.pkl\", \"rb\")\n",
    "    snapshot = cPickle.load(open(\"snapshot50.pkl\", \"rb\"), encoding=\"latin1\")\n",
    "    W0 = snapshot[\"W0\"]\n",
    "    b0 = snapshot[\"b0\"].reshape((300, 1))\n",
    "    W1 = snapshot[\"W1\"]\n",
    "    b1 = snapshot[\"b1\"].reshape((10, 1))\n",
    "    return W0,b0,W1,b1\n",
    "\n",
    "# L0, L1, output = forward(x, W0, b0, W1, b1)\n",
    "# y = argmax(output)\n",
    "\n",
    "# y_true = array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]).T\n",
    "# print(deriv_multilayer(W0, b0, W1, b1,x, L0, L1, output, y_true))\n",
    "################################################################################\n",
    "# Code for displaying a feature from the weight matrix mW\n",
    "# fig = figure(1)\n",
    "# ax = fig.gca()\n",
    "# heatmap = ax.imshow(W0[:, 50].reshape((28, 28)), cmap=cm.coolwarm)\n",
    "# fig.colorbar(heatmap, shrink=0.5, aspect=5)\n",
    "# show()\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch(offset,example_per_class=5):\n",
    "    # 5 examples per class\n",
    "    classes_num = 10\n",
    "    x_batch = np.zeros((example_per_class * classes_num, 28 * 28))\n",
    "    y_batch = np.zeros((example_per_class * classes_num, classes_num))\n",
    "    for i in range(classes_num):\n",
    "        for j in range(example_per_class):\n",
    "            x_batch[i * example_per_class + j] = M['train' + str(i)][j +\n",
    "                                                                     offset]\n",
    "            y_batch[i * example_per_class + j][i] = 1\n",
    "    return x_batch, y_batch, example_per_class * classes_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load one example from the training set, and run it through the\n",
    "def test_image(x):\n",
    "    _,_, output = forward(x, W0, b0, W1, b1)\n",
    "    return argmax(output)\n",
    "\n",
    "def test_performance_mult():\n",
    "    hit = miss = 0\n",
    "    for i in range(10):\n",
    "        for image in M[\"test\" + str(i)]:\n",
    "            result = test_image(image.reshape(784,1))\n",
    "            if result == i:\n",
    "                hit+=1\n",
    "            else:\n",
    "                miss+=1\n",
    "    return (float(hit)/float(hit + miss) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do gradient descent\n",
    "def train(plot=False):\n",
    "    global W0, b0, W1, b1\n",
    "    plot_iters = []\n",
    "    plot_performance = []\n",
    "    alpha = 1e-3\n",
    "    for i in range(150):\n",
    "        X, Y, examples_n = get_batch(i * 5,20)\n",
    "\n",
    "        update = np.zeros(4)\n",
    "\n",
    "        for j in range(examples_n):\n",
    "            y = Y[j].reshape((10, 1))\n",
    "            x = X[j].reshape((28 * 28, 1)) / 255.\n",
    "            L0, L1, output = forward(x, W0, b0, W1, b1)\n",
    "            gradients = deriv_multilayer(W0, b0, W1, b1, x, L0, L1, output, y)\n",
    "            update = [update[k] + gradients[k] for k in range(len(gradients))]\n",
    "\n",
    "        # update the weights \n",
    "        W1 -= alpha * update[0]\n",
    "        b1 -= alpha * update[1]\n",
    "        W0 -= alpha * update[2]\n",
    "        b0 -= alpha * update[3]\n",
    "        if plot:\n",
    "            plot_iters.append(i * examples_n)\n",
    "            plot_performance.append(test_perf())\n",
    "    return plot_iters,plot_performance\n",
    "W0,b0,W1,b1 = load_sample_weights()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_descent(f, df, x, y, init_t, alpha):\n",
    "    EPS = 1e-5\n",
    "    prev_t = init_t-10*EPS\n",
    "    t = init_t.copy()\n",
    "    max_iter = 10000\n",
    "    iter  = 0\n",
    "    while iter < max_iter:\n",
    "        prev_t = t.copy()\n",
    "        t -= alpha*df(x, y, t)\n",
    "        if iter % 500 == 0:\n",
    "            print(\"Iter\", iter)\n",
    "#             print \"f(x) = {}\".format(t[0], t[1], t[2], f(x, y, t))\n",
    "#             print \"Gradient: \", df(x, y, t), \"\\n\"\n",
    "        iter += 1\n",
    "    return t\n",
    "\n",
    "def test_performance_linear(theta):\n",
    "    hit = miss = 0\n",
    "    for i in range(10):\n",
    "        for image in M[\"test\" + str(i)]:\n",
    "            result = np.dot(np.append(ones(1),image),theta.T)\n",
    "            if result.argmax() == i:\n",
    "                hit+=1\n",
    "            else:\n",
    "                miss+=1\n",
    "    return (float(hit)/float(hit + miss) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Iter 500\n",
      "Iter 1000\n",
      "Iter 1500\n",
      "Iter 2000\n",
      "Iter 2500\n",
      "Iter 3000\n",
      "Iter 3500\n",
      "Iter 4000\n",
      "Iter 4500\n",
      "Iter 5000\n",
      "Iter 5500\n",
      "Iter 6000\n",
      "Iter 6500\n",
      "Iter 7000\n",
      "Iter 7500\n",
      "Iter 8000\n",
      "Iter 8500\n",
      "Iter 9000\n",
      "Iter 9500\n"
     ]
    }
   ],
   "source": [
    "def f(x, y, theta,bias=True):\n",
    "    if bias:\n",
    "        x = hstack((ones((x.shape[0],1)), x))\n",
    "    return sum(sum((y - dot(x,theta.T)) ** 2))\n",
    "\n",
    "\n",
    "def df(x, y, theta,bias=True):\n",
    "    if bias:\n",
    "        x = hstack( (ones((x.shape[0],1)), x))\n",
    "    return 2 * dot((dot(x,theta.T) - y).T,x)\n",
    "\n",
    "X,Y,n = get_batch(0,150)\n",
    "X = X/255.\n",
    "theta0 = np.zeros(10 * 785)\n",
    "theta0 = theta0.reshape(10,785)\n",
    "theta0 = grad_descent(f, df, X, Y, theta0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear performance      | 81.10\n",
      "Multinomial performance | 87.06\n"
     ]
    }
   ],
   "source": [
    "result_lin = test_performance_linear(theta0)\n",
    "result_mult = test_performance_mult()\n",
    "print(\"Linear performance      | %.2f\" % result_lin)\n",
    "print(\"Multinomial performance | %.2f\" % result_mult)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "9f653140-596b-4ece-983f-6b6a0765482c",
    "theme": {
     "11bff249-c502-4f61-a38e-5981accf77e9": {
      "id": "11bff249-c502-4f61-a38e-5981accf77e9",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     },
     "789f2b12-a5e2-45e2-a9f3-007920927d25": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "789f2b12-a5e2-45e2-a9f3-007920927d25",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "9f653140-596b-4ece-983f-6b6a0765482c": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "9f653140-596b-4ece-983f-6b6a0765482c",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         0,
         43,
         54
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         232,
         213
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         38,
         139,
         210
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         147,
         161,
         161
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Oswald",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Oswald"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Lato",
       "font-size": 5
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
